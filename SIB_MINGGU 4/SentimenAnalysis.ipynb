{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d94a18-8f18-4329-9b92-0ddf319f7602",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAMA  : NASWA DINA AMALIA\n",
    "KELAS : ALPHA (PAGI)\n",
    "\n",
    "SENTIMEN ANALISIS MENGGUNAKAN ALGORITMA NAIVE BAYES, RANDOM FOREST, SVM, DECISION TREE, DAN LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a64cf2a9-623e-49ae-988f-6745096c5b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\anaconda\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in d:\\anaconda\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: nltk in d:\\anaconda\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: sastrawi in d:\\anaconda\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in d:\\anaconda\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\anaconda\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in d:\\anaconda\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\anaconda\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\anaconda\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: click in d:\\anaconda\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\anaconda\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda\\lib\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas scikit-learn nltk sastrawi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4518c397-71a2-4a40-b1f0-275ac23c06e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   Tweet     Label\n",
      "0      warung ini dimiliki oleh pengusaha pabrik tahu...  positive\n",
      "1      mohon ulama lurus dan k212 mmbri hujjah partai...   neutral\n",
      "2      lokasi strategis di jalan sumatera bandung . t...  positive\n",
      "3      betapa bahagia nya diri ini saat unboxing pake...  positive\n",
      "4      duh . jadi mahasiswa jangan sombong dong . kas...  negative\n",
      "...                                                  ...       ...\n",
      "12755  film tncfu , tidak cocok untuk penonton yang t...  negative\n",
      "12756  indihome ini mahal loh bayar nya . hanya , pen...  negative\n",
      "12757  be de gea , cowok cupu yang takut dengan pacar...  negative\n",
      "12758  valen yang sangat tidak berkualitas . konentat...  negative\n",
      "12759  restoran ini menjadi tempat pilihan saya berbu...  positive\n",
      "\n",
      "[12760 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('Indonlu_Sentiment.xlsx')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4e78cb-741e-4fc0-bc40-fdb142d89168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menggunakan Proses Stemming\n",
    "import string\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "factory=StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords') # Inisialisasi stemmer Sastrawi\n",
    "def preprocess_text(text):\n",
    "    text = text.lower() # Mengubah teks ke huruf kecil\n",
    "    text = text.translate (str.maketrans('', '', string.punctuation)) # Menghapus tanda baca\n",
    "    text = ' '.join(stemmer.stem(word) for word in text.split()) # Stemming\n",
    "    stop_words = set(stopwords.words('indonesian')) # Menghapus stopwords\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    return text\n",
    "    \n",
    "#Terapkan preprocessing\n",
    "df['cleaned_Tweet'] = df['Tweet'].apply(preprocess_text)\n",
    "print(df[['Tweet', 'cleaned_Tweet']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2ca521b-c8b3-497f-a832-aac01ef56832",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\NASWA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   Tweet  \\\n",
      "0      warung ini dimiliki oleh pengusaha pabrik tahu...   \n",
      "1      mohon ulama lurus dan k212 mmbri hujjah partai...   \n",
      "2      lokasi strategis di jalan sumatera bandung . t...   \n",
      "3      betapa bahagia nya diri ini saat unboxing pake...   \n",
      "4      duh . jadi mahasiswa jangan sombong dong . kas...   \n",
      "...                                                  ...   \n",
      "12755  film tncfu , tidak cocok untuk penonton yang t...   \n",
      "12756  indihome ini mahal loh bayar nya . hanya , pen...   \n",
      "12757  be de gea , cowok cupu yang takut dengan pacar...   \n",
      "12758  valen yang sangat tidak berkualitas . konentat...   \n",
      "12759  restoran ini menjadi tempat pilihan saya berbu...   \n",
      "\n",
      "                                           cleaned_Tweet  \n",
      "0      warung dimiliki pengusaha pabrik puluhan terke...  \n",
      "1      mohon ulama lurus k212 mmbri hujjah partai diw...  \n",
      "2      lokasi strategis jalan sumatera bandung nya ny...  \n",
      "3      betapa bahagia nya unboxing paket barang nya b...  \n",
      "4      duh mahasiswa sombong kasih kartu kuning belaj...  \n",
      "...                                                  ...  \n",
      "12755              film tncfu cocok penonton suka sadis2  \n",
      "12756  indihome mahal loh bayar nya penanganan nya la...  \n",
      "12757  be de gea cowok cupu takut pacar nya pacar nya...  \n",
      "12758  valen berkualitas konentator nya mendidik jebr...  \n",
      "12759  restoran pilihan berbuka puasa minggu pelayana...  \n",
      "\n",
      "[12760 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Tanpa Proses Stemming\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords') # Inisialisasi stopwords NLTK\n",
    "def preprocess_text(text):\n",
    "    text = text.lower() # Mengubah teks ke huruf kecil\n",
    "    text = text.translate (str.maketrans('', '', string.punctuation)) # Menghapus tanda baca\n",
    "    stop_words = set(stopwords.words('indonesian')) # Menghapus stopwords\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    return text\n",
    "    \n",
    "# Terapkan preprocessing\n",
    "df['cleaned_Tweet'] = df['Tweet'].apply(preprocess_text)\n",
    "print(df[['Tweet', 'cleaned_Tweet']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c98af46a-1964-42ac-9dfc-fdcecf72f395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "['00' '000' '005' ... 'zupazupa' 'zuppa' 'zwitsal']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Vektorisasi teks\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['cleaned_Tweet'])\n",
    "\n",
    "# Tampilkan hasil vektorisasi\n",
    "print(X.toarray()) # Hasil vektorisasi dalam bentuk array\n",
    "print(vectorizer.get_feature_names_out()) # Fitur yang dihasilkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e4d8f13-4f43-4244-9f5e-b6d97bd720bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (9570, 18911), Test shape: (3190, 18911)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Memisahkan fitur dan Label\n",
    "y = df['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 42 )\n",
    "print(f'Train shape: {X_train.shape}, Test shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af801e94-b941-4212-a8d8-76e8d3a71ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi Naive Bayes: 0.7793103448275862\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.67      0.70      1065\n",
      "     neutral       0.97      0.21      0.35       320\n",
      "    positive       0.79      0.95      0.86      1805\n",
      "\n",
      "    accuracy                           0.78      3190\n",
      "   macro avg       0.83      0.61      0.64      3190\n",
      "weighted avg       0.79      0.78      0.76      3190\n",
      "\n",
      "Akurasi Random Forest: 0.8087774294670846\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.73      0.74      1065\n",
      "     neutral       0.84      0.43      0.57       320\n",
      "    positive       0.84      0.92      0.88      1805\n",
      "\n",
      "    accuracy                           0.81      3190\n",
      "   macro avg       0.81      0.69      0.73      3190\n",
      "weighted avg       0.81      0.81      0.80      3190\n",
      "\n",
      "Akurasi SVM: 0.8197492163009404\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.78      0.75      1065\n",
      "     neutral       0.85      0.45      0.59       320\n",
      "    positive       0.87      0.91      0.89      1805\n",
      "\n",
      "    accuracy                           0.82      3190\n",
      "   macro avg       0.82      0.71      0.74      3190\n",
      "weighted avg       0.82      0.82      0.81      3190\n",
      "\n",
      "Akurasi Decision Tree: 0.7467084639498432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.69      0.67      1065\n",
      "     neutral       0.62      0.46      0.53       320\n",
      "    positive       0.83      0.83      0.83      1805\n",
      "\n",
      "    accuracy                           0.75      3190\n",
      "   macro avg       0.70      0.66      0.67      3190\n",
      "weighted avg       0.75      0.75      0.74      3190\n",
      "\n",
      "Akurasi Logistic Regression: 0.8275862068965517\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.77      0.77      1065\n",
      "     neutral       0.84      0.51      0.63       320\n",
      "    positive       0.86      0.92      0.89      1805\n",
      "\n",
      "    accuracy                           0.83      3190\n",
      "   macro avg       0.82      0.73      0.76      3190\n",
      "weighted avg       0.83      0.83      0.82      3190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Membangun model Naive Bayes\n",
    "nb_model = MultinomialNB() \n",
    "nb_model.fit(X_train, y_train) # Memprediksi Label untuk data uji \n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "print(\"Akurasi Naive Bayes:\", accuracy_score(y_test, y_pred_nb))# Evaluasi model\n",
    "print(classification_report (y_test, y_pred_nb))\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "print(\"Akurasi Random Forest:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Support Vector Machine (SVM)\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "print(\"Akurasi SVM:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train, y_train)\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "print(\"Akurasi Decision Tree:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "print(\"Akurasi Logistic Regression:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d683955-3ffb-4140-8ecc-ead88c95f592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediksi sentimen (Naive Bayes): negative\n",
      "Prediksi sentimen (Random Forest): negative\n",
      "Prediksi sentimen (SVM): negative\n",
      "Prediksi sentimen (Decision Tree): negative\n",
      "Prediksi sentimen (Logistic Regression): negative\n"
     ]
    }
   ],
   "source": [
    "# Fungsi untuk memprediksi sentimen dari teks baru\n",
    "def predict_sentiment(text, model, vectorizer):\n",
    "    cleaned_text = preprocess_text(text)\n",
    "    text_vector = vectorizer.transform([cleaned_text])\n",
    "    prediction = model.predict(text_vector)\n",
    "    return prediction [0]\n",
    "    \n",
    "# Contoh prediksi\n",
    "new_text = \"bikin macet saja nih orang\"\n",
    "print(\"Prediksi sentimen (Naive Bayes):\", predict_sentiment(new_text, nb_model, vectorizer))\n",
    "print(\"Prediksi sentimen (Random Forest):\", predict_sentiment(new_text, rf_model, vectorizer))\n",
    "print(\"Prediksi sentimen (SVM):\", predict_sentiment(new_text, svm_model, vectorizer))\n",
    "print(\"Prediksi sentimen (Decision Tree):\", predict_sentiment(new_text, dt_model, vectorizer))\n",
    "print(\"Prediksi sentimen (Logistic Regression):\", predict_sentiment(new_text, lr_model, vectorizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e837828-be78-4574-b86c-62595cb5668c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
